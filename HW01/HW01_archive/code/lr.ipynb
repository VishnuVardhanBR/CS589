{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8412629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cases: 242\n",
      "Test cases: 61\n",
      "Feature dimensions: 18\n",
      "Training error rate: 0.12396694214876033\n",
      "Test error rate: 0.16393442622950818\n"
     ]
    }
   ],
   "source": [
    "#To install packages needed to run this code, use: pip install -r requirements.txt\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import sklearn.model_selection\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# fetch dataset \n",
    "data = fetch_ucirepo(id=45)\n",
    "\n",
    "#Convert to binary classification (no heart disease vs heart disease)\n",
    "y = data.data.targets.to_numpy().reshape(-1) \n",
    "y = np.clip(y, 0, 1)  \n",
    "\n",
    "#Impute missing values with mode\n",
    "df = data.data.features\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "#Get feature values  \n",
    "X = df.to_numpy() \n",
    "\n",
    "#Reencode categorical variables\n",
    "categorical_columns       = ['cp','restecg']\n",
    "categorical_indices       = [i for i,c in enumerate(df.columns) if c in categorical_columns]\n",
    "non_categorical_indices   = [i for i,c in enumerate(df.columns) if c not in categorical_columns]\n",
    "encoder                   = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "Xonehot                   = encoder.fit_transform(X[:,categorical_indices])\n",
    "Xnew                      = np.hstack([X[:,non_categorical_indices],Xonehot])\n",
    "\n",
    "#Split into train and test sets\n",
    "Xtrain, Xtest, ytrain, ytest = sklearn.model_selection.train_test_split(Xnew, y, test_size=0.20, random_state=589,stratify=y)\n",
    "\n",
    "#Standardize features\n",
    "scaler = StandardScaler()\n",
    "Xtrain= scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.fit_transform(Xtest)\n",
    "\n",
    "# Report dataset sizes and feature dimensions\n",
    "print(\"Training cases:\", Xtrain.shape[0])\n",
    "print(\"Test cases:\", Xtest.shape[0])\n",
    "print(\"Feature dimensions:\", Xtrain.shape[1])\n",
    "\n",
    "# Train logistic regression model\n",
    "lr = LogisticRegression(max_iter=1000, random_state=589)\n",
    "lr.fit(Xtrain, ytrain)\n",
    "\n",
    "# Predictions\n",
    "ytrain_pred = lr.predict(Xtrain)\n",
    "ytest_pred  = lr.predict(Xtest)\n",
    "\n",
    "# Compute error rates\n",
    "train_error = np.mean(ytrain_pred != ytrain)\n",
    "test_error  = np.mean(ytest_pred != ytest)\n",
    "\n",
    "print(\"Training error rate:\", train_error)\n",
    "print(\"Test error rate:\", test_error)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "689",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
